---
title: "text mining"
author: "Christina"
date: "11/29/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(tidytext)
library(tidyr)
library(dplyr)
library(stringr)
library(ggplot2)
library(gutenbergr)
library(wordcloud)
library(reshape2)
```

```{r}
jane <- gutenberg_download(1260)

tidy_books <-jane %>%
  mutate(
    linenumber = row_number(),
    chapter = cumsum(str_detect(text, 
                                regex("^chapter [\\divxlc]", 
                                      ignore_case = TRUE)))) %>%
  unnest_tokens(word, text)

#remove stop words
data("stop_words")

tidy_books<-tidy_books %>%
  anti_join(stop_words)

length(unique(tidy_books$chapter))
count(tidy_books, chapter)
#find the most common words
tidy_books %>%
  count(word, sort = TRUE)

#visualization of the most common words
tidy_books %>%
  count(word, sort = TRUE) %>%
  filter(n > 200) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(n, word)) +
  geom_col() +
  labs(y = NULL)

tidy_jane<- tidy_books %>%
  anti_join(stop_words)
```

#Sentiment analysis with inner join

```{r}
nrc_joy<-get_sentiments("nrc") %>%
  filter(sentiment == "joy")

tidy_books %>%
  inner_join(nrc_joy) %>%
  count(word, sort = TRUE)
```

#using "bing"

```{r}
#calculate negative and positive sentiment
jane_sentiment<-tidy_books %>%
  inner_join(get_sentiments("bing")) %>%
  count(index = linenumber %/% 60, sentiment) %>%
  pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>%
  mutate(sentiment = positive - negative)

#plot sentiment scores
ggplot(jane_sentiment,aes(index, sentiment,)) +
  geom_col(show.legend = FALSE) 
  
```

#comparing the three sentiment dictionaries

```{r}
afinn<-tidy_books %>%
  inner_join(get_sentiments("afinn")) %>%
  group_by(index = linenumber %/% 60) %>%
  summarise(sentiment = sum(value)) %>%
  mutate(method = "AFINN")

bing_and_nrc<-bind_rows(
  tidy_books %>%
    inner_join(get_sentiments("bing")) %>%
    mutate(method = "Bing at al."),
  tidy_books %>%
    inner_join(get_sentiments("nrc") %>%
                 filter(sentiment %in% c("positive","negative"))
               ) %>%
    mutate(method = "NRC")) %>%
  count(method, index = linenumber %/% 60, sentiment) %>%
  pivot_wider(names_from = sentiment,
              values_from = n,
              values_fill = 0) %>%
  mutate(sentiment = positive - negative)

#visualize
bind_rows(afinn,
          bing_and_nrc) %>%
  ggplot(aes(index, sentiment, fill = method)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~method, ncol = 1, scales = "free_y")

#Why the result for the NRC lexicon biased so high in sentiment compared to the Bing et al. result?
get_sentiments("nrc") %>%
  filter(sentiment %in% c("positive", "negative")) %>%
  count(sentiment)

get_sentiments("bing") %>%
  count(sentiment)
```
#Most common positive and negative words

```{r}
bing_word_counts<-tidy_books %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  ungroup()

bing_word_counts

#visualization
bing_word_counts %>%
  group_by(sentiment) %>%
  slice_max(n, n = 10) %>%
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(n, word, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(x = "Contribution to sentiment",
       y = NULL)
```

#Wordclouds

```{r}
tidy_books %>%
  anti_join(stop_words) %>%
  count(word) %>%
  with(wordcloud(word, n, max.words = 100))

#in other functions
tidy_books %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  acast(word ~ sentiment, value.var = "n", fill = 0) %>%
  comparison.cloud(colors = c("gray20", "gray80"),
                   max.words = 100)
```

#Looking at units beyond just words

```{r}
p_and_p_sentences<-tibble(text = janeeyre) %>%
  unnest_tokens(sentence, text, token = "sentences")
```

#Task three
```{r}
library(devtools)
devtools::install_github("Truenumbers/tnum/tnum")

#'tnum' package
library(knitr)
library(gutenbergr)
library(tidyverse)
library(tnum)

tnum.authorize("mssp1.bu.edu")

tnum.getDBPathList(taxonomy = "subject", levels = 3)
tnum.setSpace("test2")

#jane_eyre<-gutenberg_download(gutenberg_id = 1260)  ## download Jane Eyre
jane_eyre_txt<-readLines("jane.txt")
source("Book2TN-v3-hw.R")

#tnBooksFromLines(jane_eyre_txt, "je")


## not run: tnBooksFromLines(jane_eyre$text, "jane_eyre")

tnum.getDBPathList(taxonomy = "subject", levels = 2)
```


```{r echo=TRUE, warning=FALSE, message=FALSE}
q111 <- tnum.query(query = "jane_eyre# has ordinal", max=500)   ## everything
df111 <- tnum.objectsToDf(q111)

## show ordered objects in document
q112 <- tnum.query("jane_eyre# has ordinal")   ## show ordered objects in document
df112 <- tnum.objectsToDf(q112)

## focus on one paragraph -- note the word count for each sentence
q3 <- tnum.query("jane_eyre/section:0001/paragraph:0005# has count#")  # just 1 para
df3 <- tnum.objectsToDf(q3) %>% filter(date == "2021-12-03")
df3


## and now look at the text in a sentence
q1 <- tnum.query("jane_eyre/section:0001/paragraph:0005/sentence:0002# has text")
df1 <- tnum.objectsToDf(q1) %>% filter(date == "2021-12-03")
df1

## To extract a paragraph of text
q4 <- tnum.query("jane_eyre/section:0001/paragraph:0005/sentence# has text", max = 10)
df4 <- tnum.objectsToDf(q4) %>% filter(date == "2021-12-03")
para_text4 <- df4 %>% pull(string.value) %>% 
                      str_replace_all("\"","") %>% 
                      str_flatten(collapse = " ")

## steps to understand
# a <- para_text4[4]
# a
# 
# b <- str_replace_all(a,"\"","")   
# b
# 
# c <- para_text4
# c
# 
# c <- str_replace_all(a,"\"","")  
# 
```

# Use tnum in text analysis

```{r}
##  The ordinal numbers for the entire book 
##  show the sequence of objects in order of their appearance.
w10 <- tnum.query("jane_eyre# has ordinal", max=1800)
wdf10 <- tnum.objectsToDf(w10)

## Examing the first 50 TNs  makes it easy to see the Table of Contents
## and to see that object 22 is the heading at the start of Chapter 1


## This shows the Table of Contents
w11 <- tnum.query("jane_eyre# has text", start = 3 ,max=18)
wdf11 <- tnum.objectsToDf((w11))

table_of_contents <- wdf11 %>% select(string.value) 


## Look at just the headings shows the structure of the book
w13 <- tnum.query("jane_eyre/heading# has text", max=40)
wdf13 <- tnum.objectsToDf(w13)


## It may look like the table of contents is repeated twice,
## but examing the ordinals produces chapter list that includes the 
## ordinal location for the heading of each chapter
w14 <- tnum.query("jane_eyre/heading# has ordinal", max=40)
wdf14 <- tnum.objectsToDf(w14)

chapter_locations <- left_join(select(wdf13, subject, string.value), 
                               select(wdf14, subject, numeric.value)) 
## add column for chapter number
library(magrittr)
chapter_locations %<>% mutate(chapter=1:24)

w15 <- tnum.query("jane_eyre/section:0011# has ordinal")
wdf15 <- tnum.objectsToDf(w15)



#a <- chapter_locations %>% filter(chapter==2) %>% 
                           select(numeric.value) %>% 
                           unlist()

#a <- str_pad(as.character(a),4,side="left",pad="0")

#b <- paste0("wells12/hw12/section:",a,"#", " has ordinal")

#b


## chapter 1 para 1, word counts for the 3 sentences in para 1
q20 <- tnum.query("jane_eyre# has *", max=3)
df20 <- tnum.objectsToDf(q20)

#  chapter locations  ordinal numbers
ord_ch1 <- unlist(tnum.query("jane_eyre/heading:0011# has ordinal"))
ord_ch2 <- unlist(tnum.query("jane_eyre/heading:0012# has ordinal"))


ch1_txt <- tnum.query("jane_eyre/section:0011/paragraph:0002/# has text", max=30)

ch1_txt_df <- tnum.objectsToDf(ch1_txt)
ch1_txt_df$string.value

ch2_txt <- tnum.query("jane_eyre/section:0011/paragraph:0002/sentence:# has *", max=30)
ch2_txt_df <- tnum.objectsToDf(ch2_txt)

ch2_txt_df$string.value

length(ch2_txt_df$string.value)


q21 <- tnum.query("jane_eyre/section:0011/paragraph:0001/# has *", max = 30)
df21 <- tnum.objectsToDf(q21)


####Before
#Explore the TNs that contain Jane Eyre text
## use query to check TNs
q20<-tnum.query("jane_eyre# has *",max = 3)
df20<-tnum.objectsToDf(q20)

q24<-tnum.query("jane_eyre/heading# has *",max = 60)
df24<-tnum.objectsToDf(q24)

q11<-tnum.query("jane_eyre/heading:0011# has *")
df11<-tnum.objectsToDf(q11)
ord_ch1<-unlist(tnum.query("jane_eyre/heading:0011# has ordinal"))

ord_ch2<-unlist(tnum.query("jane_eyre/heading:0012# has ordinal"))

q25<-tnum.query("jane_eyre/heading:0012# has *")
df25<-tnum.objectsToDf(q25)

ch1_txt<-tnum.query("jane_eyre/section:0011/paragraph:0002/# has text", max = 30)
ch1_txt_df<-tnum.objectsToDf(ch1_txt)
ch1_txt_df$string.value

ch2_txt<-tnum.query("jane_eyre/section:0011/paragraph:0002/sentence:# has *", max = 30)
ch2_txt_df<-tnum.objectsToDf(ch2_txt)
ch2_txt_df$string.value

length(ch2_txt_df$string.value)

q11<-tnum.query("jane_eyre/section:0011/paragraph:0001/# has *", max = 30)
df11<-tnum.objectsToDf(q11)
```

#Sentimentr

```{r}
library(sentimentr)
jane_1 <- get_sentences(para_text4)

## to get sentiment scores by sentence
sentiment(jane_1)

## to get sentiment scores aggregated by paragraph
sentiment_by(jane_1)

```

#Sense and Sensibility

```{r}
#create tags
tnum.tagByQuery("jane_eyre/# has*= REGEXP(\"friend\")",adds = ("ref:friend"))

tnum.tagByQuery("jane_eyre/# has*=REGEXP(\"Jane|Helen\")",adds = ("ref:JH"))


#make plots(before making plots, I create a function to turn all the chapters into a vector)
getchapter<-function(query_t2){
  n= length(query_t2)
  chapterlist<-1:n
  for (i in 1:n) {
    chapterlist[i]<-
      as.character(substring(str_split(tnum.getAttrFromList(query_t2[i], "subject"), "[:/]")[[1]][4], 9))
  }
  return(chapterlist)
}

#love
friend<-tnum.query("@ref:friend", max = 20)
friend_df<-tnum.objectsToDf(friend)

ggplot() + geom_bar(mapping = aes(getchapter(friend)), stat = "count")+
  labs(x="Chapter", title = "Frequency of 'friend'")

#JE
jh<-tnum.query("@ref:JH", max = 50)
jh_df<-tnum.objectsToDf(jh)
ggplot() + geom_bar(mapping = aes(getchapter(je)), stat = "count") +
  labs(x="Chapter", title = "Frequency of Jane and Edward")

#JR
jr<-tnum.query("@ref:JR", max = 50)
jrdf<-tnum.objectsToDf(jr)
ggplot() + geom_bar(mapping = aes(getchapter(jr)), stat = "count") +
  labs(x="Chapter", title = "Frequency of Jane and Rochester")


```

## Couples with love

```{r}
friendjh<-tnum.query("@[ref:friend,ref:JH]", max = 50)

```



## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
